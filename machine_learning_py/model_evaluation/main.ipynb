{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699472377405337"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler# Load digits dataset\n",
    "digits = datasets.load_digits()\n",
    "# Create features matrix\n",
    "features = digits.data\n",
    "# Create target vector\n",
    "target = digits.target\n",
    "# Create standardizer\n",
    "standardizer = StandardScaler()\n",
    "# Create logistic regression object\n",
    "logit = LogisticRegression()\n",
    "# Create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# Conduct k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "features, # Feature matrix\n",
    "target, # Target vector\n",
    "cv=kf, # Cross-validation technique\n",
    "scoring=\"accuracy\", # Loss function\n",
    "n_jobs=-1) # Use all CPU scores\n",
    "# Calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98888889, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View score for all 10 folds\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### when we fit our standardization object, standardizer, we calculate the mean and variance of only the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Create training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, test_size=0.1, random_state=1)\n",
    "# Fit standardizer to training set\n",
    "standardizer.fit(features_train)\n",
    "# Apply to both training and test sets\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
