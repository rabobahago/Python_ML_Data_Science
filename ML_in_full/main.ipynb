{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transforms\n",
    "- Rescale Data\n",
    "- Standardize Data\n",
    "- Normalize Data\n",
    "- Binarize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35 0.74 0.59 0.35 0.   0.5  0.23 0.48]\n",
      " [0.06 0.43 0.54 0.29 0.   0.4  0.12 0.17]\n",
      " [0.47 0.92 0.52 0.   0.   0.35 0.25 0.18]\n",
      " [0.06 0.45 0.54 0.23 0.11 0.42 0.04 0.  ]\n",
      " [0.   0.69 0.33 0.35 0.2  0.64 0.94 0.2 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import set_printoptions\n",
    "from pandas import read_csv\n",
    "filename = 'data/diabetes.csv'\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "X\n",
    "Y = array[:, 8]\n",
    "Y\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX =scaler.fit_transform(X)\n",
    "set_printoptions(precision=2)\n",
    "print(rescaledX[0: 5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
      " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
      " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names = names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[: , 0:8]\n",
    "Y = array[:, 8]\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The values for each attribute now have a mean value of 0 and a standard deviation of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called a unit norm or a vector with the length of 1 in linear algebra). This pre-processing method can be useful for sparse datasets (lots of zeros) with attributes of varying scales when using algorithms that weight input values such as neural networks and algorithms that use distancemeasures such as k-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n",
      " [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n",
      " [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n",
      " [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n",
      " [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "scalerX = Normalizer().fit(X)\n",
    "rescaledX = scalerX.transform(X)\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize Data (Make Binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can transform your data using a binary threshold. All values above the threshold are marked 1 and all equal to or below are marked as 0. This is called binarizing your data or thresholding your data. It can be useful when you have probabilities that you want to make crisp values. It is also useful when feature engineering and you want to add new features that indicate something meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from pandas import read_csv\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0: 8]\n",
    "Y = array[:, 8]\n",
    "scalerX =Binarizer(threshold=0.0).fit(X)\n",
    "rescaledX =scalerX.transform(X)\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data features that you use to train your machine learning models have a huge influence on the performance you can achieve. Irrelevant or partially relevant features can negatively impact model performanc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Univariate Selection.\n",
    "- Recursive Feature Elimination.\n",
    "- Principle Component Analysis.\n",
    "- Feature Importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plas', 'test', 'mass', 'age']\n",
      "[ 111.52  1411.887   17.605   53.108 2175.565  127.669    5.393  181.304]\n",
      "[['148' '0' '33.6' '50']\n",
      " ['85' '0' '26.6' '31']\n",
      " ['183' '0' '23.3' '32']\n",
      " ['89' '94' '28.1' '21']\n",
      " ['137' '168' '43.1' '33']]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "test =SelectKBest(score_func=chi2, k =4)\n",
    "fit = test.fit(X, Y)\n",
    "select_features_indices = fit.get_support(indices=True)\n",
    "names = [names[i] for i in select_features_indices]\n",
    "print(names)\n",
    "set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "print(features[0:5, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preg', 'plas', 'mass', 'pedi']\n",
      "Num Features: 4\n",
      "Select Features: [ True  True False False False  True  True False]\n",
      "Features Ranking: [1 1 3 4 5 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "model =LogisticRegression()\n",
    "rfe = RFE(model)\n",
    "fit = rfe.fit(X, Y)\n",
    "select_features_indices = fit.get_support(indices=True)\n",
    "names = [names[i] for i in select_features_indices]\n",
    "print(names)\n",
    "print(\"Num Features:\", fit.n_features_)\n",
    "print('Select Features:', fit.support_)\n",
    "print('Features Ranking:', fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.889 0.062 0.026]\n",
      ".................................\n",
      "[[-2.022e-03  9.781e-02  1.609e-02  6.076e-02  9.931e-01  1.401e-02\n",
      "   5.372e-04 -3.565e-03]\n",
      " [-2.265e-02 -9.722e-01 -1.419e-01  5.786e-02  9.463e-02 -4.697e-02\n",
      "  -8.168e-04 -1.402e-01]\n",
      " [-2.246e-02  1.434e-01 -9.225e-01 -3.070e-01  2.098e-02 -1.324e-01\n",
      "  -6.400e-04 -1.255e-01]]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "pca =PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "print(\"Explained Variance:\", fit.explained_variance_ratio_)\n",
    "print('.................................')\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.111 0.227 0.101 0.078 0.077 0.142 0.117 0.146]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# load data\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train and Test Sets.\n",
    "- k-fold Cross Validation.\n",
    "- Leave One Out Cross Validation.\n",
    "- Repeated Random Test-Train Splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.7\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import set_printoptions\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "test_size = .33\n",
    "seeds = 7\n",
    "train_X,test_X, train_Y, test_Y =train_test_split(X, Y, test_size=test_size, random_state=seeds)\n",
    "model = LogisticRegression()\n",
    "model.fit(train_X, train_Y)\n",
    "set_printoptions(precision=3)\n",
    "result = model.score(test_X, test_Y)\n",
    "accuracy = \"accuracy: {:.3g}\".format(result * 100)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Mean: 76.8 std: 5.19\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "test_size = .33\n",
    "seed = 7\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "accuracy_mean = \"{:.3g}\".format(results.mean()*100.0)\n",
    "accuracy_std = \"{:.3g}\".format(results.std()*100.0)\n",
    "print(\"Accuracy: Mean: {} std: {}\".format(accuracy_mean, accuracy_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: mean: 77.86458333333334, std: 41.51584029812865\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "num_folds = 10\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "print(\"Accuracy: mean: {}, std: {}\".format(results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated Random Test-Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=> mean: 77.087, std: 2.929\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "num_folds = 10\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy=> mean: {:.3f}, std: {:.3f}\".format(results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics\n",
    "- Classification Accuracy.\n",
    "- Logarithmic Loss.\n",
    "- Area Under ROC Curve.\n",
    "- Confusion Matrix.\n",
    "- Classification Report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: => Mean: 76.823%, std: 5.191%\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: => Mean: {:.3f}%, std: {:.3f}%\".format(results.mean() * 100, results.std() *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_log_loss: => mean: -0.487, std:0.064\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LogisticRegression()\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"neg_log_loss: => mean: {:.3f}, std:{:.3f}\".format(results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: => mean: 0.825, std:0.043\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LogisticRegression()\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"roc_auc: => mean: {:.3f}, std:{:.3f}\".format(results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142  20]\n",
      " [ 34  58]]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       162\n",
      "           1       0.74      0.63      0.68        92\n",
      "\n",
      "    accuracy                           0.79       254\n",
      "   macro avg       0.78      0.75      0.76       254\n",
      "weighted avg       0.78      0.79      0.78       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Report\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Mean Absolute Error (or MAE) is the sum of the absolute differences between predictions and actual values. It gives an idea of how wrong the predictions were. The measure gives an idea of the magnitude of the error, but no idea of the direction (e.g. over or under predicting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: Mean: -4.020, std: 2.083\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename,  delim_whitespace=True, names=names)\n",
    "\n",
    "array = dataframe.values[1:]\n",
    "X = array[:, 0:13]\n",
    "Y = array[:, 13]\n",
    "test_size = 0.33\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MAE: Mean: {:.3f}, std: {:.3f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: Mean: -34.705, std: 45.574\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MSE\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MSE: Mean: {:.3f}, std: {:.3f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: Mean: 0.203, std: 0.595\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MSE\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"R^2: Mean: {:.3f}, std: {:.3f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Spot-Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7682330827067668\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773462064251538\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265550239234451\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes calculates the probability of each class and the conditional probability of each class given each input value. These probabilities are estimated for new data and multiplied together, assuming that they are all independent (a simple or naive assumption)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7551777170198223\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = GaussianNB()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Regression Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6977614490772387\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = DecisionTreeClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (or SVM) seek a line that best separates two classes. Those data instances that are closest to the line that best separates the classes are called support vectors and influence where the line is placed. SVM has been extended to support multiple classes. Of particular importance is the use of different kernel functions via the kernel parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604237867395763\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = SVC()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot-Check Regression Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Starting with four linear machine learning algorithms:\n",
    "- Linear Regression.\n",
    "- Ridge Regression.\n",
    "- LASSO Linear Regression.\n",
    "- Elastic Net Regression.\n",
    "  \n",
    "Then looking at three nonlinear machine learning algorithms:\n",
    "- k-Nearest Neighbors.\n",
    "- Classification and Regression Trees.\n",
    "- Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression assumes that the input variables have a Gaussian distribution. It is also assumed that input variables are relevant to the output variable and that they are not highly correlated with each other (a problem called collinearity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.814121714050025\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values[1: ]\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.124986688332825\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = Ridge()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.763033848950826\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = Lasso()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet is a form of regularization regression that combines the properties of both Ridge Regression and LASSO regression. It seeks to minimize the complexity of the regression model (magnitude and number of regression coefficients) by penalizing the model using both the L2-norm (sum squared coefficient values) and the L1-norm (sum absolute coefficient values). You can construct an ElasticNet model using the ElasticNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-31.16457371424976\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = ElasticNet()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-107.28683898039215\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = KNeighborsRegressor()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification and Regression Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-33.52219137254902\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = DecisionTreeRegressor()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM) were developed for binary classification. The technique has been extended for the prediction real-valued problems called Support Vector Regression (SVR). Like the classification example, SVR is built upon the LIBSVM library. You can create an SVM model for regression using the SVR class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-72.25543311855311\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = SVR()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Machine Learning Algorithms Consistently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression.\n",
    "- Linear Discriminant Analysis.\n",
    "- k-Nearest Neighbors.\n",
    "- Classification and Regression Trees.\n",
    "- Naive Bayes.\n",
    "- Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.768233 (0.051906)\n",
      "LDA: 0.773462 (0.051592)\n",
      "KNN: 0.726555 (0.061821)\n",
      "CART: 0.686107 (0.058723)\n",
      "NB: 0.755178 (0.042766)\n",
      "SVM: 0.760424 (0.052931)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "filename = 'data/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values[1:]\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=None)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
