{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Figure Settings\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "import ipywidgets as widgets\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Helper Functions\n",
    "\n",
    "def checkExercise1(A, B, C, D):\n",
    "  \"\"\"\n",
    "  Helper function for checking Exercise 1.\n",
    "\n",
    "  Args:\n",
    "    A: torch.Tensor\n",
    "      Torch Tensor of shape (20, 21) consisting of ones.\n",
    "    B: torch.Tensor\n",
    "      Torch Tensor of size([3,4])\n",
    "    C: torch.Tensor\n",
    "      Torch Tensor of size([20,21])\n",
    "    D: torch.Tensor\n",
    "      Torch Tensor of size([19])\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  assert torch.equal(A.to(int),torch.ones(20, 21).to(int)), \"Got: {A} \\n Expected: {torch.ones(20, 21)} (shape: {torch.ones(20, 21).shape})\"\n",
    "  assert np.array_equal(B.numpy(),np.vander([1, 2, 3], 4)), \"Got: {B} \\n Expected: {np.vander([1, 2, 3], 4)} (shape: {np.vander([1, 2, 3], 4).shape})\"\n",
    "  assert C.shape == (20, 21), \"Got: {C} \\n Expected (shape: {(20, 21)})\"\n",
    "  assert torch.equal(D, torch.arange(4, 41, step=2)), \"Got {D} \\n Expected: {torch.arange(4, 41, step=2)} (shape: {torch.arange(4, 41, step=2).shape})\"\n",
    "  print(\"All correct\")\n",
    "\n",
    "def timeFun(f, dim, iterations, device='cpu'):\n",
    "  \"\"\"\n",
    "  Helper function to calculate amount of time taken per instance on CPU/GPU\n",
    "\n",
    "  Args:\n",
    "    f: BufferedReader IO instance\n",
    "      Function name for which to calculate computational time complexity\n",
    "    dim: Integer\n",
    "      Number of dimensions in instance in question\n",
    "    iterations: Integer\n",
    "      Number of iterations for instance in question\n",
    "    device: String\n",
    "      Device on which respective computation is to be run\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  iterations = iterations\n",
    "  t_total = 0\n",
    "  for _ in range(iterations):\n",
    "    start = time.time()\n",
    "    f(dim, device)\n",
    "    end = time.time()\n",
    "    t_total += end - start\n",
    "\n",
    "  if device == 'cpu':\n",
    "    print(f\"time taken for {iterations} iterations of {f.__name__}({dim}, {device}): {t_total:.5f}\")\n",
    "  else:\n",
    "    print(f\"time taken for {iterations} iterations of {f.__name__}({dim}, {device}): {t_total:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = ((1, 2), (3, 6))\n",
    "torch.tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = np.ones([2,4])\n",
    "one = torch.tensor(one)\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor x: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Tensor y: tensor([0., 0.])\n",
      "Tensor z: tensor([[[-5.3203e+36,  7.4409e-43,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# The numerical arguments we pass to these constructors\n",
    "# determine the shape of the output tensor\n",
    "\n",
    "x = torch.ones(5, 3)\n",
    "y = torch.zeros(2)\n",
    "z = torch.empty(1, 1, 5)\n",
    "print(f\"Tensor x: {x}\")\n",
    "print(f\"Tensor y: {y}\")\n",
    "print(f\"Tensor z: {z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor random: tensor([[0.8519, 0.5154, 0.0190]])\n",
      "Tensor mean 1 and std 0: tensor([[ 0.8546, -0.0234, -1.5640],\n",
      "        [-1.2728, -0.3340,  1.5390]])\n",
      "Tensor of random like: tensor([[0., 0., 0.]])\n",
      "Tensor of random like: tensor([[0.3895, 0.1772, 0.3815]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, 3)\n",
    "b = torch.randn(2, 3)\n",
    "c = torch.zeros_like(a)\n",
    "d = torch.rand_like(c)\n",
    "print(f\"Tensor random: {a}\")\n",
    "print(f\"Tensor mean 1 and std 0: {b}\")\n",
    "print(f\"Tensor of random like: {c}\")\n",
    "print(f\"Tensor of random like: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x295737755d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "Numpy array b: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "Tensor c: tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000,\n",
      "        4.5000, 5.0000])\n",
      "\n",
      "Numpy array d: [0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0, 10, step=1)\n",
    "b = np.arange(0, 10, step=1)\n",
    "\n",
    "c = torch.linspace(0, 5, steps=11)\n",
    "d = np.linspace(0, 5, num=11)\n",
    "\n",
    "print(f\"Tensor a: {a}\\n\")\n",
    "print(f\"Numpy array b: {b}\\n\")\n",
    "print(f\"Tensor c: {c}\\n\")\n",
    "print(f\"Numpy array d: {d}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All correct\n"
     ]
    }
   ],
   "source": [
    "def tensor_creation(Z):\n",
    "  \"\"\"\n",
    "  A function that creates various tensors.\n",
    "\n",
    "  Args:\n",
    "    Z: numpy.ndarray\n",
    "      An array of shape (3,4)\n",
    "\n",
    "  Returns:\n",
    "    A : Tensor\n",
    "      20 by 21 tensor consisting of ones\n",
    "    B : Tensor\n",
    "      A tensor with elements equal to the elements of numpy array  Z\n",
    "    C : Tensor\n",
    "      A tensor with the same number of elements as A but with values âˆ¼U(0,1)\n",
    "    D : Tensor\n",
    "      A 1D tensor containing the even numbers between 4 and 40 inclusive.\n",
    "  \"\"\"\n",
    "\n",
    "  A = torch.ones(20, 21)\n",
    "  B = torch.Tensor(Z)\n",
    "  C = torch.rand_like(A)\n",
    "  D = torch.arange(4, 41, step=2)\n",
    "\n",
    "  return A, B, C, D\n",
    "\n",
    "\n",
    "# numpy array to copy later\n",
    "Z = np.vander([1, 2, 3], 4)\n",
    "\n",
    "# Uncomment below to check your function!\n",
    "A, B, C, D = tensor_creation(Z)\n",
    "checkExercise1(A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3702, 0.7656, 0.7404],\n",
      "        [0.6731, 0.4856, 0.5747],\n",
      "        [0.5022, 0.1371, 0.6161],\n",
      "        [0.1324, 0.7426, 0.2021],\n",
      "        [0.3367, 0.2629, 0.8947]])\n",
      "tensor([[1.3702, 1.7656, 1.7404],\n",
      "        [1.6731, 1.4856, 1.5747],\n",
      "        [1.5022, 1.1371, 1.6161],\n",
      "        [1.1324, 1.7426, 1.2021],\n",
      "        [1.3367, 1.2629, 1.8947]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5, 3)\n",
    "b = torch.rand(5, 3)\n",
    "c = torch.empty(5, 3)\n",
    "d = torch.empty(5, 3)\n",
    "mul = torch.mul(a, b, out = c)\n",
    "add = torch.add(a, b, out= d)\n",
    "#pointwise operators\n",
    "print(mul)\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2,  4,  7, 12]),\n",
       " tensor([0, 0, 1, 4]),\n",
       " tensor([ 1,  4, 12, 32]),\n",
       " tensor([1.0000, 1.0000, 1.3333, 2.0000]),\n",
       " tensor([   1,    4,   64, 4096]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elementwise operators\n",
    "x = torch.tensor([1, 2, 4, 8])\n",
    "y = torch.tensor([1, 2, 3, 4])\n",
    "x + y, x - y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7778, 0.9162, 0.7569],\n",
      "        [0.5188, 0.9309, 0.2063],\n",
      "        [0.9716, 0.9886, 0.9776]])\n",
      "sum:  tensor(7.0447)\n",
      "sum rowwise:  tensor([2.2682, 2.8357, 1.9409])\n",
      "sum columnwise:  tensor([2.4509, 1.6560, 2.9378])\n",
      "\n",
      "\n",
      "Mean value of all elements of x 0.7827451825141907\n",
      "Mean values of the columns of x tensor([0.7561, 0.9452, 0.6470])\n",
      "Mean values of the rows of x tensor([0.8170, 0.5520, 0.9793])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 3)\n",
    "print(x)\n",
    "print('sum: ', x.sum())\n",
    "print('sum rowwise: ', x.sum(axis=0))\n",
    "print('sum columnwise: ', x.sum(axis=1))\n",
    "print('\\n')\n",
    "print(f\"Mean value of all elements of x {x.mean()}\")\n",
    "print(f\"Mean values of the columns of x {x.mean(axis=0)}\")\n",
    "print(f\"Mean values of the rows of x {x.mean(axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20, 24],\n",
      "        [31, 27]])\n"
     ]
    }
   ],
   "source": [
    "def simple_operations(a1: torch.Tensor, a2: torch.Tensor, a3: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Helper function to demonstrate simple operations\n",
    "    i.e., Multiplication of tensor a1 with tensor a2 and then add it with tensor a3\n",
    "\n",
    "    Args:\n",
    "        a1: Torch tensor\n",
    "        Tensor of size ([2,2])\n",
    "        a2: Torch tensor\n",
    "        Tensor of size ([2,2])\n",
    "        a3: Torch tensor\n",
    "        Tensor of size ([2,2])\n",
    "\n",
    "    Returns:\n",
    "        answer: Torch tensor\n",
    "        Tensor of size ([2,2]) resulting from a1 multiplied with a2, added with a3\n",
    "    \"\"\"\n",
    "\n",
    "    answer = torch.add(torch.matmul(a1, a2), a3)\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "# init our tensors\n",
    "a1 = torch.tensor([[2, 4], [5, 7]])\n",
    "a2 = torch.tensor([[1, 1], [2, 3]])\n",
    "a3 = torch.tensor([[10, 10], [12, 1]])\n",
    "## uncomment to test your function\n",
    "A = simple_operations(a1, a2, a3)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(82)\n"
     ]
    }
   ],
   "source": [
    "def dot_product(b1: torch.Tensor, b2: torch.Tensor):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper function to demonstrate dot product operation\n",
    "    Dot product is an algebraic operation that takes two equal-length sequences\n",
    "    (usually coordinate vectors), and returns a single number.\n",
    "    Geometrically, it is the product of the Euclidean magnitudes of the\n",
    "    two vectors and the cosine of the angle between them.\n",
    "\n",
    "    Args:\n",
    "        b1: Torch tensor\n",
    "        Tensor of size ([3])\n",
    "        b2: Torch tensor\n",
    "        Tensor of size ([3])\n",
    "\n",
    "    Returns:\n",
    "        product: Tensor\n",
    "        Tensor of size ([1]) resulting from b1 scalar multiplied with b2\n",
    "    \"\"\"\n",
    "    # Use torch.dot() to compute the dot product of two tensors\n",
    "    product = torch.dot(b1, b2)\n",
    "    return product\n",
    "\n",
    "\n",
    "# Computing expression 2:\n",
    "b1 = torch.tensor([3, 5, 7])\n",
    "b2 = torch.tensor([2, 4, 8])\n",
    "## Uncomment to test your function\n",
    "b = dot_product(b1, b2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor(9)\n",
      "tensor([1, 2])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 10)\n",
    "print(x)\n",
    "print(x[-1])\n",
    "print(x[1:3])\n",
    "print(x[:-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of x[0]:torch.Size([2, 3, 4, 5])\n",
      " shape of x[0][0]:torch.Size([3, 4, 5])\n",
      " shape of x[0][0][0]:torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# make a 5D tensor\n",
    "x = torch.rand(1, 2, 3, 4, 5)\n",
    "\n",
    "print(f\" shape of x[0]:{x[0].shape}\")\n",
    "print(f\" shape of x[0][0]:{x[0][0].shape}\")\n",
    "print(f\" shape of x[0][0][0]:{x[0][0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n",
      "flatten to the original elements: \n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "reshape: \n",
      " tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.arange(12).reshape(2, 6)\n",
    "print(f'Original:\\n{z}')\n",
    "x = z.flatten()\n",
    "print(f'flatten to the original elements: \\n {x}')\n",
    "y = x.reshape(3, 4)\n",
    "print(f'reshape: \\n {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5429, -0.5430,  1.3089, -0.1468, -0.7791, -0.5856,  0.0736,  0.9282,\n",
      "         -0.7914,  0.9528]])\n",
      "torch.Size([1, 10])\n",
      "x[0]: tensor([ 0.5429, -0.5430,  1.3089, -0.1468, -0.7791, -0.5856,  0.0736,  0.9282,\n",
      "        -0.7914,  0.9528])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 10)\n",
    "# printing the zeroth element of the tensor will not give us the first number!\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(f\"x[0]: {x[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "x[0]: 0.5428665280342102\n"
     ]
    }
   ],
   "source": [
    "# Let's get rid of that singleton dimension and see what happens now\n",
    "x = x.squeeze(0)\n",
    "print(x.shape)\n",
    "print(f\"x[0]: {x[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y: torch.Size([5, 5])\n",
      "Shape of y: torch.Size([5, 1, 5])\n",
      "tensor([[[-0.5565, -1.1817, -0.9822, -1.4188,  0.5159]],\n",
      "\n",
      "        [[-0.7512,  0.2989,  0.0790,  1.9876,  0.4388]],\n",
      "\n",
      "        [[ 0.3811,  1.7162, -0.0039, -2.0564, -1.5919]],\n",
      "\n",
      "        [[-2.0217,  0.7896,  1.1842,  0.6712, -1.0036]],\n",
      "\n",
      "        [[ 0.4756,  0.8377,  0.8374, -1.2132,  0.4991]]])\n"
     ]
    }
   ],
   "source": [
    "# Adding singleton dimensions works a similar way, and is often used when tensors\n",
    "# being added need same number of dimensions\n",
    "\n",
    "y = torch.randn(5, 5)\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# lets insert a singleton dimension\n",
    "y = y.unsqueeze(1)\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 23, 45])\n",
      "torch.Size([45, 34, 23])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(23, 34, 45)\n",
    "x = x.permute(1, 0, 2)\n",
    "print(x.shape)\n",
    "# same but in a different format\n",
    "# can only swap two at a time\n",
    "x = x.transpose(2, 1)\n",
    "x = x.transpose(1, 0)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "tensor([[2., 1., 4., 3.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [4., 3., 2., 1.]])\n",
      "Concatenated by rows: shape[6, 4] \n",
      " tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [ 2.,  1.,  4.,  3.],\n",
      "        [ 1.,  2.,  3.,  4.],\n",
      "        [ 4.,  3.,  2.,  1.]])\n",
      "\n",
      " Concatenated by colums: shape[3, 8]  \n",
      " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
      "        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors of the same shape\n",
    "x = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "print(x)\n",
    "y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(y)\n",
    "# Concatenate along rows\n",
    "cat_rows = torch.cat((x, y), dim=0)\n",
    "\n",
    "# Concatenate along columns\n",
    "cat_cols = torch.cat((x, y), dim=1)\n",
    "\n",
    "# Printing outputs\n",
    "print('Concatenated by rows: shape{} \\n {}'.format(list(cat_rows.shape), cat_rows))\n",
    "print('\\n Concatenated by colums: shape{}  \\n {}'.format(list(cat_cols.shape), cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([-1.0868,  0.1153, -2.7522,  0.1934,  0.7367])  |  x type:  torch.FloatTensor\n",
      "y: [-1.0867969   0.11530989 -2.752199    0.19335043  0.7367095 ]  |  y type:  <class 'numpy.ndarray'>\n",
      "z: tensor([-1.0868,  0.1153, -2.7522,  0.1934,  0.7367])  |  z type:  torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5)\n",
    "print(f\"x: {x}  |  x type:  {x.type()}\")\n",
    "\n",
    "y = x.numpy()\n",
    "print(f\"y: {y}  |  y type:  {type(y)}\")\n",
    "\n",
    "z = torch.tensor(y)\n",
    "print(f\"z: {z}  |  z type:  {z.type()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24, 24])\n"
     ]
    }
   ],
   "source": [
    "def functionA(my_tensor1, my_tensor2):\n",
    "  \"\"\"\n",
    "  This function takes in two 2D tensors `my_tensor1` and `my_tensor2`\n",
    "  and returns the column sum of\n",
    "  `my_tensor1` multiplied by the sum of all the elmements of `my_tensor2`,\n",
    "  i.e., a scalar.\n",
    "\n",
    "  Args:\n",
    "    my_tensor1: torch.Tensor\n",
    "    my_tensor2: torch.Tensor\n",
    "\n",
    "  Returns:\n",
    "    output: torch.Tensor\n",
    "      The multiplication of the column sum of `my_tensor1` by the sum of\n",
    "      `my_tensor2`.\n",
    "  \"\"\"\n",
    "  output = my_tensor1.sum(axis=1) * my_tensor2.sum()\n",
    "\n",
    "  return output\n",
    "\n",
    "## Implement the functions above and then uncomment the following lines to test your code\n",
    "print(functionA(torch.tensor([[1, 1], [1, 1]]), torch.tensor([[1, 2, 3], [1, 2, 3]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[ 2],\n",
      "        [ 3],\n",
      "        [-1],\n",
      "        [10]])\n",
      "tensor([[ 0,  2],\n",
      "        [ 1,  3],\n",
      "        [ 2, -1],\n",
      "        [ 3, 10]])\n"
     ]
    }
   ],
   "source": [
    "def functionB(my_tensor):\n",
    "  \"\"\"\n",
    "  This function takes in a square matrix `my_tensor` and returns a 2D tensor\n",
    "  consisting of a flattened `my_tensor` with the index of each element\n",
    "  appended to this tensor in the row dimension.\n",
    "\n",
    "  Args:\n",
    "    my_tensor: torch.Tensor\n",
    "\n",
    "  Returns:\n",
    "    output: torch.Tensor\n",
    "      Concatenated tensor.\n",
    "  \"\"\"\n",
    "  # TODO flatten the tensor `my_tensor`\n",
    "  my_tensor = my_tensor.flatten()\n",
    "  # TODO create the idx tensor to be concatenated to `my_tensor`\n",
    "  idx_tensor = torch.arange(0, len(my_tensor))\n",
    "  print(idx_tensor.unsqueeze(1))\n",
    "  print(my_tensor.unsqueeze(1))\n",
    "  # TODO concatenate the two tensors\n",
    "  output = torch.cat([idx_tensor.unsqueeze(1), my_tensor.unsqueeze(1)], axis=1)\n",
    "\n",
    "  return output\n",
    "\n",
    "## Implement the functions above and then uncomment the following lines to test your code\n",
    "\n",
    "print(functionB(torch.tensor([[2, 3], [-1, 10]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3,  2],\n",
      "        [-1,  5]])\n",
      "tensor([ 1, -1, -1,  3,  2,  3,  0])\n"
     ]
    }
   ],
   "source": [
    "def functionC(my_tensor1, my_tensor2):\n",
    "  \"\"\"\n",
    "  This function takes in two 2D tensors `my_tensor1` and `my_tensor2`.\n",
    "  If the dimensions allow it, it returns the\n",
    "  elementwise sum of `my_tensor1`-shaped `my_tensor2`, and `my_tensor2`;\n",
    "  else this function returns a 1D tensor that is the concatenation of the\n",
    "  two tensors.\n",
    "\n",
    "  Args:\n",
    "    my_tensor1: torch.Tensor\n",
    "    my_tensor2: torch.Tensor\n",
    "\n",
    "  Returns:\n",
    "    output: torch.Tensor\n",
    "      Concatenated tensor.\n",
    "  \"\"\"\n",
    "  # TODO check we can reshape `my_tensor2` into the shape of `my_tensor1`\n",
    "  if torch.numel(my_tensor1) == torch.numel(my_tensor2):\n",
    "    # TODO reshape `my_tensor2` into the shape of `my_tensor1`\n",
    "    my_tensor2 = my_tensor2.reshape(my_tensor1.shape)\n",
    "    # TODO sum the two tensors\n",
    "    output = my_tensor1 + my_tensor2\n",
    "  else:\n",
    "    # TODO flatten both tensors\n",
    "    my_tensor1 = my_tensor1.reshape(1, -1)\n",
    "    my_tensor2 = my_tensor2.reshape(1, -1)\n",
    "    # TODO concatenate the two tensors in the correct dimension\n",
    "    output = torch.cat([my_tensor1, my_tensor2], axis=1).squeeze()\n",
    "\n",
    "  return output\n",
    "print(functionC(torch.tensor([[1, -1], [-1, 3]]), torch.tensor([[2, 3, 0, 2]])))\n",
    "print(functionC(torch.tensor([[1, -1], [-1, 3]]), torch.tensor([[2, 3, 0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
